{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pymorphy2\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1:  Сравнение стилей текстов\n",
    "### Выполнили:  Булгаков Дмитрий, Тефикова Алие\n",
    "### Группа ИАД-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составьте самостоятельно как минимум две коллекции\n",
    "текстов разных стилей (например, коллекция текстов в публицистическом\n",
    "стиле и коллекция текстов в научном стиле). Коллекции текстов\n",
    "должны быть достаточно большие (порядка 5000 токенов). Посчитайте\n",
    "количество токенов и типов в каждой коллекции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Получение  данных из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_control_characters(text_string):\n",
    "    return ''.join(filter(None, text_string.splitlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Загрузка художественных текстов (Портрет Дориана Грея,  Оскар Уайльд)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "«Портре́т Дориана Гре́я» (англ. The Picture of Dorian Gray) — единственный опубликованный роман Оскара Уайльда. В жанровом отношении представляет смесь романа воспитания с моральной притчей. Существует в двух версиях — в 13 главах (1890 года) и в 20 главах (1891 года). Стал самым успешным произведением Уайльда, более 30 раз экранизировался."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Link:<b> http://lib.ru/WILDE/doriangray.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fiction = open('data/dorian_gray.txt', encoding='utf-8').read()\n",
    "fiction = remove_control_characters(fiction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Загрузка  публицистических текстов (статьи lenta.ru) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lenta.ru — одно из ведущих российских новостных интернет-изданий, основанное в 1999 году Антоном Носиком при содействии Фонда эффективной политики. Работает круглосуточно, освещая мировые и внутрироссийские новости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Link<b>: http://lenta.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "journalistic = open('data/lentaru.txt', encoding='utf-8').read()\n",
    "journalistic = remove_control_characters(journalistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Загрузка  научных текстов (Молодежная Наука 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы Всероссийской научно-практической конференции молодых ученых, аспирантов и студентов, посвященной 150-летию со дня рождения профессора В.Н. Варгина (Пермь, 14-18 марта 2016 года)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Link<b>: http://pgsha.ru/web/science/scientificarticles/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scientific = open('data/perm_conf.txt', encoding='utf-8').read()\n",
    "scientific = remove_control_characters(scientific)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Загрузка  текстов  разговорного стиля (корпус составленный на базе Twitter )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве источника текстов была выбрана платформа микроблогинга Twitter. Современные поисковые системы и имеющиеся в открытом доступе инструменты по сбору текстовых отзывов не позволяют собирать актуальные отзывы и оперативно работать с данными. В связи с этим на основе программного интерефейса API twitter  был разработан программный инструмент для извлечения отзывов об интересующих товарах, услугах,  событиях,  персонах из микроблоггинг-платформы twitter,  который позволяет учитывать время публикации сообщения и авторитетность автора сообщения. Этот инструмент использовался для сбора неразмеченного корпуса. В корпусе содержится более 15 миллионов записей за время с конца ноября 2013 года до конца февраля 2014 года."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Link:<b> http://study.mokoron.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conversational = open('data/twitter.txt', encoding='utf-8').read()\n",
    "conversational = remove_control_characters(conversational)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Подсчет токенов и типов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude_symbols = set(punctuation + '0123456789'+u'–—'+u'«»'+u'“')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text, exlude_symb):\n",
    "    text = text.lower()\n",
    "    text_merged = ''.join(ch for ch in text if ch not in exlude_symb)\n",
    "    text_tokens = WhitespaceTokenizer().tokenize(text_merged.lower())\n",
    "    return text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(tokens):\n",
    "    print('N of tokens: ', len(tokens))\n",
    "    types = nltk.FreqDist(tokens)\n",
    "    print('N of types:', len(types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Токены и типы для  художественного стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of tokens:  60528\n",
      "N of types: 18236\n"
     ]
    }
   ],
   "source": [
    "fiction_tokens = tokenize(fiction, exclude_symbols)\n",
    "print_results(fiction_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Токены и типы для публицистического стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of tokens:  13699\n",
      "N of types: 6015\n"
     ]
    }
   ],
   "source": [
    "journalistic_tokens = tokenize(journalistic, exclude_symbols)\n",
    "print_results(journalistic_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Токены и типы для  научного стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of tokens:  265376\n",
      "N of types: 57790\n"
     ]
    }
   ],
   "source": [
    "scientific_tokens = tokenize(scientific, exclude_symbols)\n",
    "print_results(scientific_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Токены и типы для  разговорного стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of tokens:  255367\n",
      "N of types: 56878\n"
     ]
    }
   ],
   "source": [
    "conversational_tokens = tokenize(conversational, exclude_symbols)\n",
    "print_results(conversational_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Подсчет частей речи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Подсчет частоты вхождений слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('russian') + [u'это', u'№', u'гсха', u'это', u'оо', u'изз', u'б']\n",
    "morph_analyzer = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word_freq_count(tokens, morph, stopwords=None):\n",
    "    lemmata = nltk.FreqDist()\n",
    "    types = nltk.FreqDist(tokens)\n",
    "    \n",
    "    for t in types:\n",
    "        l = morph.parse(t)[0].normal_form\n",
    "        if l in lemmata:\n",
    "            lemmata[l] += types[t]\n",
    "        else:\n",
    "            lemmata[l] = types[t]\n",
    "                \n",
    "    if (stopwords != None):\n",
    "        lemmata = lemmata_remove_stopwords(lemmata, stopwords)\n",
    "    \n",
    "    return lemmata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmata_remove_stopwords(lem, stopwords):\n",
    "    lem_no_sw = nltk.FreqDist()\n",
    "    for l in lem:\n",
    "        if not l in stopwords:\n",
    "            lem_no_sw[l] = lem[l]\n",
    "    return lem_no_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_lemata_most_common(lem, count=10):\n",
    "    print('N of lemmata:', len(lem))\n",
    "    \n",
    "    for i in lem.most_common(count):\n",
    "        print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_count_analysis(tokens, morph, stopwords):\n",
    "    print('Без исключения стоп-слов:\\n')\n",
    "    lem_no_stop = word_freq_count(tokens, morph)\n",
    "    print_lemata_most_common(lem_no_stop)\n",
    "    \n",
    "    print('\\n\\nИсключая стоп-слова:\\n')\n",
    "    lem_stop = word_freq_count(tokens, morph, stopwords)\n",
    "    print_lemata_most_common(lem_stop)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Частота вхождений слов для художественного стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Без исключения стоп-слов:\n",
      "\n",
      "N of lemmata: 11980\n",
      "и 1914\n",
      "он 1773\n",
      "в 1585\n",
      "я 1477\n",
      "не 1211\n",
      "вы 913\n",
      "что 904\n",
      "быть 729\n",
      "на 725\n",
      "с 689\n",
      "\n",
      "\n",
      "Исключая стоп-слова:\n",
      "\n",
      "N of lemmata: 11871\n",
      "дориан 670\n",
      "весь 451\n",
      "человек 296\n",
      "который 282\n",
      "свой 277\n",
      "лорд 253\n",
      "генри 243\n",
      "жизнь 226\n",
      "сказать 225\n",
      "мочь 196\n"
     ]
    }
   ],
   "source": [
    "perform_count_analysis(fiction_tokens, morph_analyzer, stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Частота вхождений слов для публицистического стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Без исключения стоп-слов:\n",
      "\n",
      "N of lemmata: 4027\n",
      "в 713\n",
      "и 299\n",
      "на 243\n",
      "что 177\n",
      "с 174\n",
      "о 171\n",
      "год 138\n",
      "это 135\n",
      "по 135\n",
      "не 106\n",
      "\n",
      "\n",
      "Исключая стоп-слова:\n",
      "\n",
      "N of lemmata: 3941\n",
      "год 138\n",
      "февраль 101\n",
      "россия 84\n",
      "который 78\n",
      "также 51\n",
      "российский 42\n",
      "заявить 42\n",
      "мочь 39\n",
      "сообщить 38\n",
      "стать 34\n"
     ]
    }
   ],
   "source": [
    "perform_count_analysis(journalistic_tokens, morph_analyzer, stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Частота вхождений слов для научного стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Без исключения стоп-слов:\n",
      "\n",
      "N of lemmata: 39007\n",
      "в 9598\n",
      "и 9005\n",
      "на 4623\n",
      "с 3570\n",
      "по 2310\n",
      "год 2245\n",
      "для 1584\n",
      "от 1449\n",
      "что 1329\n",
      "при 1182\n",
      "\n",
      "\n",
      "Исключая стоп-слова:\n",
      "\n",
      "N of lemmata: 38901\n",
      "год 2245\n",
      "пермский 1086\n",
      "который 962\n",
      "производство 888\n",
      "являться 812\n",
      "продукция 804\n",
      "развитие 727\n",
      "предприятие 681\n",
      "хозяйство 674\n",
      "сельскохозяйственный 651\n"
     ]
    }
   ],
   "source": [
    "perform_count_analysis(scientific_tokens, morph_analyzer, stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Частота вхождений слов для разговорного стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Без исключения стоп-слов:\n",
      "\n",
      "N of lemmata: 40435\n",
      "я 10214\n",
      "не 7760\n",
      "в 6501\n",
      "и 6376\n",
      "на 4281\n",
      "что 3477\n",
      "с 3452\n",
      "а 3077\n",
      "весь 3017\n",
      "ты 2850\n",
      "\n",
      "\n",
      "Исключая стоп-слова:\n",
      "\n",
      "N of lemmata: 40319\n",
      "весь 3017\n",
      "ещё 1172\n",
      "хотеть 1125\n",
      "мочь 916\n",
      "день 855\n",
      "сегодня 790\n",
      "очень 733\n",
      "просто 669\n",
      "свой 663\n",
      "хороший 594\n"
     ]
    }
   ],
   "source": [
    "perform_count_analysis(conversational_tokens, morph_analyzer, stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Подсчет количества  слов  с учетом части речи:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя любой морфологический процессор, который вам нравится (pymorphy2, mystem), определите к какой части речиотносятся слова из каждой коллекции текстов. При помощи nltk.FreqDist() составьте частотные словари: часть речи – количество слов, к ней относящихся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parts_of_speech = ['NOUN', 'ADJF', 'ADJS', 'COMP', 'VERB', \n",
    "         'INFN', 'PRTF', 'PRTS', 'GRND', 'NUMR', \n",
    "         'ADVB', 'NPRO', 'PRED', 'PREP', 'CONJ',\n",
    "         'PRCL', 'INTJ', 'OTHR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_parts_of_speech(tokens, morph, parts):\n",
    "    types = nltk.FreqDist(tokens)\n",
    "    pos_dict = {}\n",
    "    for t in types:\n",
    "        word = morph.parse(t)[0].normal_form\n",
    "        word_pos = morph.parse(word)[0].tag.POS\n",
    "        \n",
    "        if (word_pos == None):\n",
    "            word_pos = 'OTHR'\n",
    "        \n",
    "        if (word_pos in pos_dict.keys()):\n",
    "            pos_dict[word_pos] += types[t]\n",
    "        else:\n",
    "            pos_dict[word_pos] = types[t]\n",
    "        \n",
    "    return pos_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Количество слов с учетом части речи для художественного стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJF': 7597,\n",
       " 'ADJS': 61,\n",
       " 'ADVB': 3885,\n",
       " 'CONJ': 5897,\n",
       " 'GRND': 61,\n",
       " 'INFN': 11352,\n",
       " 'INTJ': 157,\n",
       " 'NOUN': 15955,\n",
       " 'NPRO': 6021,\n",
       " 'NUMR': 237,\n",
       " 'OTHR': 160,\n",
       " 'PRCL': 3369,\n",
       " 'PRED': 318,\n",
       " 'PREP': 5314,\n",
       " 'PRTF': 14,\n",
       " 'PRTS': 5,\n",
       " 'VERB': 125}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parts_of_speech(fiction_tokens, morph_analyzer, parts_of_speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Количество слов с учетом части речи для публицистического стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJF': 1796,\n",
       " 'ADJS': 2,\n",
       " 'ADVB': 333,\n",
       " 'CONJ': 746,\n",
       " 'GRND': 3,\n",
       " 'INFN': 1917,\n",
       " 'INTJ': 11,\n",
       " 'NOUN': 5985,\n",
       " 'NPRO': 233,\n",
       " 'NUMR': 83,\n",
       " 'OTHR': 302,\n",
       " 'PRCL': 297,\n",
       " 'PRED': 23,\n",
       " 'PREP': 1930,\n",
       " 'PRTF': 14,\n",
       " 'PRTS': 1,\n",
       " 'VERB': 23}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parts_of_speech(journalistic_tokens, morph_analyzer, parts_of_speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Количество слов с учетом части речи для научного стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJF': 47272,\n",
       " 'ADJS': 102,\n",
       " 'ADVB': 5697,\n",
       " 'COMP': 2,\n",
       " 'CONJ': 15460,\n",
       " 'GRND': 79,\n",
       " 'INFN': 24950,\n",
       " 'INTJ': 381,\n",
       " 'NOUN': 126169,\n",
       " 'NPRO': 2197,\n",
       " 'NUMR': 533,\n",
       " 'OTHR': 8393,\n",
       " 'PRCL': 2966,\n",
       " 'PRED': 542,\n",
       " 'PREP': 30154,\n",
       " 'PRTF': 156,\n",
       " 'PRTS': 10,\n",
       " 'VERB': 313}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parts_of_speech(scientific_tokens, morph_analyzer, parts_of_speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Количество слов с учетом части речи для разговорного стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJF': 27017,\n",
       " 'ADJS': 345,\n",
       " 'ADVB': 21903,\n",
       " 'COMP': 2,\n",
       " 'CONJ': 24190,\n",
       " 'GRND': 149,\n",
       " 'INFN': 43466,\n",
       " 'INTJ': 2082,\n",
       " 'NOUN': 65272,\n",
       " 'NPRO': 20192,\n",
       " 'NUMR': 696,\n",
       " 'OTHR': 4153,\n",
       " 'PRCL': 18255,\n",
       " 'PRED': 2184,\n",
       " 'PREP': 24617,\n",
       " 'PRTF': 40,\n",
       " 'PRTS': 34,\n",
       " 'VERB': 770}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parts_of_speech(conversational_tokens, morph_analyzer, parts_of_speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну что тут сказать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"picture.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
